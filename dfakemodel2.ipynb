{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install Keras-Applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XxZhQPnEZWKy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "import keras_video.utils\n",
        "from keras.layers import Conv2D, BatchNormalization,MaxPool2D, GlobalMaxPool2D\n",
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
        "import keras.applications\n",
        "from keras import optimizers\n",
        "#from keras_applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ARtErumNZ2bn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning, `split` argument is replaced by `split_val`, please condider to change your source code.The `split` argument will be removed in future releases.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class Fake, validation count: 118, train count: 472\n",
            "class Real, validation count: 118, train count: 472\n",
            "Total data: 2 classes for 944 files for train\n"
          ]
        }
      ],
      "source": [
        "\n",
        "classes=['Fake','Real']\n",
        "SIZE = (224, 224)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 5\n",
        "BS = 8\n",
        "glob_pattern='{classname}\\\\*.mp4'\n",
        "\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.2,\n",
        "    height_shift_range=.2)\n",
        "\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split=.20, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5dt_BwNFaRCR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total data: 2 classes for 236 files for validation\n"
          ]
        }
      ],
      "source": [
        "valid = train.get_validation_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ajw_l9n4f2YV"
      },
      "outputs": [],
      "source": [
        "def build_mobilenet(shape=(224, 224, 3), nbout=3):\n",
        "    model = keras.applications.mobilenet.MobileNet(\n",
        "        include_top=False,\n",
        "        input_shape=shape,\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train﻿﻿\n",
        "    trainable = 9\n",
        "    for layer in model.layers[:-trainable]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[-trainable:]:\n",
        "        layer.trainable = True\n",
        "    output = keras.layers.GlobalMaxPool2D()\n",
        "    return keras.Sequential([model, output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jIcJaDuham-L"
      },
      "outputs": [],
      "source": [
        "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
        "    convnet = build_mobilenet(shape[1:])\n",
        "    model = keras.Sequential()\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m8lQwDk8a0d8"
      },
      "outputs": [],
      "source": [
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'binary_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vcqHW1lja3--"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14996\\1579475556.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history=model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.7095 - acc: 0.5064"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: saving model to chkp\\weights.01-0.70.hdf5\n",
            "118/118 [==============================] - 1234s 10s/step - loss: 0.7095 - acc: 0.5064 - val_loss: 0.6965 - val_acc: 0.4978 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.6357 - acc: 0.6388"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: saving model to chkp\\weights.02-0.54.hdf5\n",
            "118/118 [==============================] - 372s 3s/step - loss: 0.6357 - acc: 0.6388 - val_loss: 0.5381 - val_acc: 0.8139 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.5843 - acc: 0.7108"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3: saving model to chkp\\weights.03-0.64.hdf5\n",
            "118/118 [==============================] - 315s 3s/step - loss: 0.5843 - acc: 0.7108 - val_loss: 0.6441 - val_acc: 0.5974 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4833 - acc: 0.8167"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4: saving model to chkp\\weights.04-0.50.hdf5\n",
            "118/118 [==============================] - 314s 3s/step - loss: 0.4833 - acc: 0.8167 - val_loss: 0.5026 - val_acc: 0.7879 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4867 - acc: 0.7818"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5: saving model to chkp\\weights.05-0.58.hdf5\n",
            "118/118 [==============================] - 313s 3s/step - loss: 0.4867 - acc: 0.7818 - val_loss: 0.5839 - val_acc: 0.6926 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4503 - acc: 0.8506"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6: saving model to chkp\\weights.06-0.49.hdf5\n",
            "118/118 [==============================] - 313s 3s/step - loss: 0.4503 - acc: 0.8506 - val_loss: 0.4877 - val_acc: 0.8182 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4275 - acc: 0.8316"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7: saving model to chkp\\weights.07-0.43.hdf5\n",
            "118/118 [==============================] - 314s 3s/step - loss: 0.4275 - acc: 0.8316 - val_loss: 0.4275 - val_acc: 0.8442 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4199 - acc: 0.8612"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8: saving model to chkp\\weights.08-0.42.hdf5\n",
            "118/118 [==============================] - 313s 3s/step - loss: 0.4199 - acc: 0.8612 - val_loss: 0.4178 - val_acc: 0.8225 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4209 - acc: 0.8506"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9: saving model to chkp\\weights.09-0.42.hdf5\n",
            "118/118 [==============================] - 315s 3s/step - loss: 0.4209 - acc: 0.8506 - val_loss: 0.4214 - val_acc: 0.8398 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4448 - acc: 0.8294"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Frame count is not OK for video Real\\id27_0005.mp4, 2 total, 1 extracted\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10: saving model to chkp\\weights.10-0.32.hdf5\n",
            "118/118 [==============================] - 315s 3s/step - loss: 0.4448 - acc: 0.8294 - val_loss: 0.3161 - val_acc: 0.9134 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "EPOCHS=10\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "]\n",
        "history=model.fit_generator(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_fd3D5TGfhli"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: MobileNet-Transfer relearning\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: MobileNet-Transfer relearning\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save('MobileNet-Transfer relearning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cap_from_youtube\n",
            "  Downloading cap_from_youtube-0.0.9-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cap_from_youtube) (4.5.5.64)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.3.4-py2.py3-none-any.whl (2.9 MB)\n",
            "     ---------------------------------------- 2.9/2.9 MB 219.5 kB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cap_from_youtube) (1.22.0)\n",
            "Collecting pycryptodomex\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-win_amd64.whl (1.7 MB)\n",
            "     ---------------------------------------- 1.7/1.7 MB 4.6 MB/s eta 0:00:00\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-win_amd64.whl (383 kB)\n",
            "     ------------------------------------- 383.3/383.3 KB 12.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp->cap_from_youtube) (2022.12.7)\n",
            "Collecting websockets\n",
            "  Downloading websockets-11.0.1-cp310-cp310-win_amd64.whl (124 kB)\n",
            "     -------------------------------------- 124.5/124.5 KB 7.1 MB/s eta 0:00:00\n",
            "Collecting mutagen\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "     -------------------------------------- 193.6/193.6 KB 3.9 MB/s eta 0:00:00\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp, cap_from_youtube\n",
            "Successfully installed brotli-1.0.9 cap_from_youtube-0.0.9 mutagen-1.46.0 pycryptodomex-3.17 websockets-11.0.1 yt-dlp-2023.3.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install cap_from_youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BvqrXlPwfkbY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from cap_from_youtube import cap_from_youtube\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "def video_read(path,fr=5):\n",
        "  frames=[]\n",
        "  video_fr=cap_from_youtube(path, 'best')\n",
        "  Total_frames=int(video_fr.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  skip_frames_window = 1\n",
        "  for frame_counter in range(fr):\n",
        "    video_fr.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "    success, frame = video_fr.read() \n",
        "    if not success:\n",
        "        break\n",
        "    cent_frame=crop_center_square(frame)\n",
        "    resized_frame = cv2.resize(cent_frame, (224,224))\n",
        "    normalized_frame = resized_frame / 255\n",
        "  \n",
        "    frames.append(normalized_frame)\n",
        "  video_fr.release()\n",
        "  while len(frames)<5:\n",
        "    frames.append(frames[0])\n",
        "  return np.array([frames])\n",
        "\n",
        "def mod(path):\n",
        "  extracted_frames=video_read(path)\n",
        "  model=tf.keras.models.load_model('D:\\\\download\\\\study\\\\Hackathon\\\\dfakedataset\\\\MobileNet-Transfer relearning')\n",
        "  pred=model.predict(extracted_frames)\n",
        "  if(pred[0,0]>pred[0,1]):\n",
        "    return('Fake')\n",
        "  else:\n",
        "    return('real')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://youtube.com/shorts/8D0SenJCqG0?feature=share\n",
            "[youtube] 8D0SenJCqG0: Downloading webpage\n",
            "[youtube] 8D0SenJCqG0: Downloading android player API JSON\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002108B0A9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002108B0A9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Fake'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mod('https://youtube.com/shorts/8D0SenJCqG0?feature=share')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting Flask>=0.8\n",
            "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
            "     -------------------------------------- 101.8/101.8 KB 1.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask-ngrok) (2.28.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->flask-ngrok) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->flask-ngrok) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->flask-ngrok) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->flask-ngrok) (3.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.0->Flask>=0.8->flask-ngrok) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Installing collected packages: itsdangerous, Flask, flask-ngrok\n",
            "Successfully installed Flask-2.2.3 flask-ngrok-0.0.25 itsdangerous-2.1.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "     -------------------------------------- 761.3/761.3 KB 4.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: PyYAML in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py): started\n",
            "  Building wheel for pyngrok (setup.py): finished with status 'done'\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19825 sha256=62c90640b4848a67a1801943e54f2f09b8318a1a772e4c40cf78abd93251c001\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\6c\\e1\\46\\8d60711cb43fb2e055fb69bb9964f91c9a5046f7924d2996ac\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask-cors) (2.2.3)\n",
            "Requirement already satisfied: Six in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask-cors) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.9->flask-cors) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.0->Flask>=0.9->flask-cors) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.1.2)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-3.0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://9cc4-2a09-bac5-3b49-11c3-00-1c5-6.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 14:55:28] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=EZ0yc5QT29M\n",
            "[youtube] EZ0yc5QT29M: Downloading webpage\n",
            "[youtube] EZ0yc5QT29M: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 14:59:07] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ck4_7HfHVb0\n",
            "[youtube] ck4_7HfHVb0: Downloading webpage\n",
            "[youtube] ck4_7HfHVb0: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:00:56] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=iyiOVUbsPcM\n",
            "[youtube] iyiOVUbsPcM: Downloading webpage\n",
            "[youtube] iyiOVUbsPcM: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:02:14] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 231ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:06:49] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002173CB59E10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 356ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:07:03] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002172AA66F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 319ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:08:21] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 210ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:08:50] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 210ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:10:30] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=iyiOVUbsPcM\n",
            "[youtube] iyiOVUbsPcM: Downloading webpage\n",
            "[youtube] iyiOVUbsPcM: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:12:34] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ck4_7HfHVb0\n",
            "[youtube] ck4_7HfHVb0: Downloading webpage\n",
            "[youtube] ck4_7HfHVb0: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 15:14:25] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=iyiOVUbsPcM\n",
            "[youtube] iyiOVUbsPcM: Downloading webpage\n",
            "[youtube] iyiOVUbsPcM: Downloading android player API JSON\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 16:15:59] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ck4_7HfHVb0\n",
            "[youtube] ck4_7HfHVb0: Downloading webpage\n",
            "[youtube] ck4_7HfHVb0: Downloading android player API JSON\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 16:17:54] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 266ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Apr/2023 16:18:25] \"POST /imagepredict HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request\n",
        "from flask_cors import CORS\n",
        "import flask\n",
        "app = Flask(__name__)\n",
        "CORS(app, resources={r\"/*\": {\"origins\": \"chrome-extension://hejngendhlbipgbcnihfgkoihpmgopjl\"}})\n",
        "run_with_ngrok(app)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "from random import sample\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from cap_from_youtube import cap_from_youtube\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "def image_read(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img_reshape=np.resize(img,(256,256,3))\n",
        "    l=np.array([img_reshape for i in range(10)])\n",
        "    return l\n",
        "\n",
        "def video_read(path,fr=10):\n",
        "  frames=[]\n",
        "  video_fr=cap_from_youtube(path, 'best')\n",
        "  Total_frames=int(video_fr.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  skip_frames_window =  max(int(Total_frames/fr), 1)\n",
        "  for frame_counter in range(fr):\n",
        "    video_fr.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "    success, frame = video_fr.read() \n",
        "    if not success:\n",
        "        break\n",
        "    cent_frame=crop_center_square(frame)\n",
        "    resized_frame = cv2.resize(cent_frame, (224,224))\n",
        "    normalized_frame = resized_frame / 255\n",
        "  \n",
        "    frames.append(normalized_frame)\n",
        "  video_fr.release()\n",
        "  while len(frames)<5:\n",
        "    frames.append(frames[0])\n",
        "  return np.array([frames])\n",
        "\n",
        "def mod(path,filetype):\n",
        "  if filetype=='image':\n",
        "    extracted_frames=image_read(path)\n",
        "    model=tf.keras.models.load_model('D:\\\\download\\\\study\\\\Hackathon\\\\dfakedataset\\\\imgmodel\\\\Modelnew')\n",
        "    pred=(model.predict(tf.cast(extracted_frames,tf.float32))+0.5).astype(np.int32)\n",
        "    if(pred.sum()>=0.25*pred.shape[0]):\n",
        "      return 'FAKE'\n",
        "    return 'REAL'\n",
        "  extracted_frames=video_read(path)\n",
        "  model=tf.keras.models.load_model('D:\\\\download\\\\study\\\\Hackathon\\\\dfakedataset\\\\MobileNet-Transfer relearning')\n",
        "  pred=model.predict(extracted_frames)\n",
        "  if(pred[0,0]>pred[0,1]):\n",
        "    return('FAKE')\n",
        "  else:\n",
        "    return('REAL')\n",
        "\n",
        "@app.route('/imagepredict', methods=['POST'])\n",
        "def imgpredict():\n",
        "    data = request.get_json() # this will extract the JSON data from the request body\n",
        "    # Do something with the data, for example:\n",
        "    input_text = data['link'] # assuming that the input data has a key 'text'\n",
        "    # Your prediction code here\n",
        "    # return 'Your prediction result' # Your predicted output\n",
        "    out=mod(input_text,'image')\n",
        "    response = flask.jsonify({'key':out})\n",
        "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
        "    return response\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json() # this will extract the JSON data from the request body\n",
        "    # Do something with the data, for example:\n",
        "    input_text = data['link'] # assuming that the input data has a key 'text'\n",
        "    # Your prediction code here\n",
        "    # return 'Your prediction result' # Your predicted output\n",
        "    out=mod(input_text,'video')\n",
        "    response = flask.jsonify({'key':out})\n",
        "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
        "    return response\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "  response = flask.jsonify({'key':'value'})\n",
        "  response.headers.add('Access-Control-Allow-Origin', '*')\n",
        "  return response\n",
        "\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def image_read(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def image_read(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img_reshape=np.resize(img,(256,256,3))\n",
        "    l=np.array([img_reshape for i in range(10)])\n",
        "    return l\n",
        "\n",
        "extracted_frames=image_read('https://storage.googleapis.com/kagglesdsdata/datasets/1909705/3134515/Dataset/Test/Real/real_1.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20230409%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230409T072326Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=e776248b4c935e6ff4bb2da7d309d1ea91fabf97f508b3b653ebabbf1967df7acf4650614439e548953a2645dce510bf87e23ed575fe301ab9718c211c57459655d292c7a09fe08b08ec25abe41e37ecf4ec09b41139394331f42f683d14bfce91afc87aa02e2b94750364bd7c0a635084f7eb2ffeec0623430f979b89cebefbfc51632aa24488e742bbdafd8922bd2d3dcccc4c6463bd109bfa7271e0a8be8870c062fc388c3e5a6d45fb8fce289e73c93202a8d201ddf9e7b22301ffa90a1e6bd4e9c18954155c540a29fd6079f88f41c9097c5fb33752d1fb9203289207e2a94f6e729a342e1d8ab467b97fabbd1554fb3ae6b3a140406b9f9ef93cc76189')\n",
        "# model=tf.keras.models.load_model('D:\\\\download\\\\study\\\\Hackathon\\\\dfakedataset\\\\imgmodel')\n",
        "# pred=(model.predict(tf.cast(extracted_frames,tf.float32))+0.5).astype(np.int32)\n",
        "# if(pred.sum()>=0.25*pred.shape[0]):\n",
        "#     print('FAKE')\n",
        "# print('REAL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=tf.keras.models.load_model('D:\\\\download\\\\study\\\\Hackathon\\\\dfakedataset\\\\imgmodel\\\\Modelnew')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002108B22B400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002108B22B400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 333ms/step\n",
            "REAL\n"
          ]
        }
      ],
      "source": [
        "pred=(model.predict(tf.cast(extracted_frames,tf.float32))+0.5).astype(np.int32)\n",
        "if(pred.sum()>=0.25*pred.shape[0]):\n",
        "    print('FAKE')\n",
        "print('REAL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
